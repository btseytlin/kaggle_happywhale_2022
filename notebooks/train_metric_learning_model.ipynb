{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install wandb timm numpy pytorch-metric-learning faiss-gpu --upgrade\n",
    "# !rm -r kaggle_happywhale_2022\n",
    "# !git clone https://github.com/btseytlin/kaggle_happywhale_2022.git\n",
    "# import sys\n",
    "# sys.path.append('kaggle_happywhale_2022')\n",
    "#\n",
    "# import wandb\n",
    "#\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     api_key = user_secrets.get_secret(\"WANDB\")\n",
    "#     wandb.login(key=api_key)\n",
    "#     anonymous = None\n",
    "# except:\n",
    "#     anonymous = \"must\"\n",
    "#     wandb.login(anonymous=anonymous)\n",
    "#     print('wand secret missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from happywhale import (ImageDataMoodule,\n",
    "                        ImageBackbone,\n",
    "                        MetricLearner,\n",
    "                        load_train_test_dfs,\n",
    "                        get_cv_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OFFLINE = False\n",
    "EXP_NAME = 'metric_learning'\n",
    "tags = ['dataset_base_128', 'backbone_efficientnet_b0', 'metric_learning', 'contrastive_loss']\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "TRAIN_IMG_DIR = '../input/jpeg-happywhale-128x128/train_images-128-128/train_images-128-128'\n",
    "TEST_IMG_DIR = '../input/jpeg-happywhale-128x128/test_images-128-128/test_images-128-128'\n",
    "TRAIN_CSV_PATH = '../input/happy-whale-and-dolphin/train.csv'\n",
    "TEST_CSV_PATH = '../input/happy-whale-and-dolphin/sample_submission.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BACKBONE = 'efficientnet_b0'\n",
    "LR = 3e-4\n",
    "BACKBONE_EMBEDDING_DIM = 1000\n",
    "EMBEDDING_SIZE = 256\n",
    "CLASS_SUBSET = 10\n",
    "\n",
    "N_EPOCHS = 4\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "\n",
    "TRAINER_KWARGS = dict(\n",
    "    max_epochs=N_EPOCHS,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    gradient_clip_val=1,\n",
    "    accumulate_grad_batches=2,\n",
    "    # stochastic_weight_avg=True,\n",
    "    # fast_dev_run=True,\n",
    ")\n",
    "\n",
    "# if DEVICE != 'cpu':\n",
    "#     TRAINER_KWARGS.update(\n",
    "#         dict(\n",
    "#             # amp_backend='apex',\n",
    "#             # amp_level='O2',\n",
    "#             # precision=16,\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Local overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAINER_KWARGS['fast_dev_run'] = 1\n",
    "TRAIN_IMG_DIR = '../data/images_128/train_images-128-128'\n",
    "TEST_IMG_DIR = '../data/images_128/test_images-128-128'\n",
    "TRAIN_CSV_PATH = '../data/train.csv'\n",
    "TEST_CSV_PATH = '../data/test.csv'\n",
    "EXP_NAME = 'LOCAL_TEST'\n",
    "OFFLINE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CV: split and prepare datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51033, 5) (27956, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_train_test_dfs(\n",
    "    train_csv_path=TRAIN_CSV_PATH,\n",
    "    test_csv_path=TEST_CSV_PATH,\n",
    "    train_images_path=TRAIN_IMG_DIR,\n",
    "    test_images_path=TEST_IMG_DIR,\n",
    ")\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 5)\n"
     ]
    }
   ],
   "source": [
    "if CLASS_SUBSET:\n",
    "    classes = train_df.individual_id.value_counts()\n",
    "    train_df = train_df[train_df.individual_id.isin(classes.head(CLASS_SUBSET).index)]\n",
    "    print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv_splits = get_cv_splits(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1400, 350)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_splits[0].train), len(cv_splits[0].val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:121: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:159: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:114: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:152: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(train_df.individual_id.values)\n",
    "\n",
    "split_datamodules = []\n",
    "for split in cv_splits:\n",
    "    split_train_df = train_df.iloc[split.train]\n",
    "    split_val_df = train_df.iloc[split.val]\n",
    "    datamodule = ImageDataMoodule(\n",
    "        train_df=split_train_df,\n",
    "        val_df=split_val_df,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        label_encoder=label_encoder,\n",
    "        # sampler='m_per_class',\n",
    "    )\n",
    "    datamodule.setup()\n",
    "    split_datamodules.append(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbtseytlin\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.11"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/btseytlin/Documents/kaggle_happywhale_2022/notebooks/wandb/run-20220319_160054-3uj8jptb</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/btseytlin/kaggle_happywhale/runs/3uj8jptb\" target=\"_blank\">LOCAL_TEST_fold_0</a></strong> to <a href=\"https://wandb.ai/btseytlin/kaggle_happywhale\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | backbone | ImageBackbone    | 5.3 M \n",
      "1 | loss     | CrossEntropyLoss | 0     \n",
      "2 | mlp      | Sequential       | 322 K \n",
      "3 | arc      | ArcMarginProduct | 2.6 K \n",
      "----------------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.455    Total estimated model params size (MB)\n",
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/Users/btseytlin/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "994192e4c50c463d8a1f289acee61373"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57205c1ccd714ac1945929e250386746"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4005c483ab70424e8fdb5866a1525a15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5762dda2291a4ecebaa794cfa0d53523"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 21] Is a directory: '/Users/btseytlin/Documents/kaggle_happywhale_2022/notebooks'\n",
      "WARNING: Couldn't load best checkpoint\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b79f0ea9e47434e9faf3f7388eb2d0e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">LOCAL_TEST_fold_0</strong>: <a href=\"https://wandb.ai/btseytlin/kaggle_happywhale/runs/3uj8jptb\" target=\"_blank\">https://wandb.ai/btseytlin/kaggle_happywhale/runs/3uj8jptb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20220319_160054-3uj8jptb/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "for i, datamodule in enumerate(split_datamodules):\n",
    "    backbone = ImageBackbone(model_name=BACKBONE)\n",
    "    model = MetricLearner(\n",
    "        backbone=backbone,\n",
    "        lr=LR,\n",
    "        num_labels=len(datamodule.label_encoder.classes_),\n",
    "        num_training_steps=len(datamodule.train)//datamodule.batch_size * N_EPOCHS,\n",
    "        trainer_kwargs=TRAINER_KWARGS,\n",
    "        backbone_embedding_dim=BACKBONE_EMBEDDING_DIM,\n",
    "        embedding_size=EMBEDDING_SIZE,\n",
    "        offline=OFFLINE,\n",
    "    )\n",
    "\n",
    "    run = wandb.init(\n",
    "        project='kaggle_happywhale',\n",
    "        name=EXP_NAME + f'_fold_{i}',\n",
    "        tags=tags,\n",
    "    )\n",
    "\n",
    "    model.fit(datamodule)\n",
    "    models.append(model.cpu())\n",
    "    run.finish()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MetricLearner(\n  (backbone): ImageBackbone(\n    (trunk): EfficientNet(\n      (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): SiLU(inplace=True)\n      (blocks): Sequential(\n        (0): Sequential(\n          (0): DepthwiseSeparableConv(\n            (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): Identity()\n          )\n        )\n        (1): Sequential(\n          (0): InvertedResidual(\n            (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (1): InvertedResidual(\n            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (2): Sequential(\n          (0): InvertedResidual(\n            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (1): InvertedResidual(\n            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (3): Sequential(\n          (0): InvertedResidual(\n            (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (1): InvertedResidual(\n            (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (2): InvertedResidual(\n            (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (4): Sequential(\n          (0): InvertedResidual(\n            (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (1): InvertedResidual(\n            (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (2): InvertedResidual(\n            (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (5): Sequential(\n          (0): InvertedResidual(\n            (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (1): InvertedResidual(\n            (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (2): InvertedResidual(\n            (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (3): InvertedResidual(\n            (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (6): Sequential(\n          (0): InvertedResidual(\n            (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): SiLU(inplace=True)\n            (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act2): SiLU(inplace=True)\n            (se): SqueezeExcite(\n              (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n              (act1): SiLU(inplace=True)\n              (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n              (gate): Sigmoid()\n            )\n            (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): SiLU(inplace=True)\n      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n      (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n    )\n  )\n  (loss): CrossEntropyLoss()\n  (mlp): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=1000, out_features=256, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=256, out_features=256, bias=True)\n    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  )\n  (arc): ArcMarginProduct()\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}